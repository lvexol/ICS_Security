{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=30, num_layers=5, dropout=0.17044, num_classes=2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        # Initialize cell state\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Get the output from the last time step\n",
    "        out = self.relu(out[:, -1, :])\n",
    "        \n",
    "        # FC layer\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to balance dataset\n",
    "def balance_dataset(X, y):\n",
    "    \"\"\"\n",
    "    Balance the dataset by upsampling the minority class\n",
    "    \"\"\"\n",
    "    X_normal = X[y == 0]\n",
    "    y_normal = y[y == 0]\n",
    "    X_attack = X[y == 1]\n",
    "    y_attack = y[y == 1]\n",
    "    \n",
    "    # Upsample minority class\n",
    "    if len(X_attack) < len(X_normal):\n",
    "        X_attack_upsampled, y_attack_upsampled = resample(\n",
    "            X_attack, y_attack,\n",
    "            replace=True,\n",
    "            n_samples=len(X_normal),\n",
    "            random_state=42\n",
    "        )\n",
    "        X_balanced = np.vstack((X_normal, X_attack_upsampled))\n",
    "        y_balanced = np.hstack((y_normal, y_attack_upsampled))\n",
    "    else:\n",
    "        X_balanced = np.vstack((X_normal, X_attack))\n",
    "        y_balanced = np.hstack((y_normal, y_attack))\n",
    "    \n",
    "    return X_balanced, y_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing function\n",
    "def preprocess_data(df, sequence_length=20):\n",
    "    \"\"\"\n",
    "    Preprocess the data including:\n",
    "    - Handling missing values\n",
    "    - Encoding categorical data\n",
    "    - Scaling features\n",
    "    - Creating sequences for LSTM\n",
    "    \"\"\"\n",
    "    # Make a copy of the dataframe to avoid modifying the original\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Identify categorical columns\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    # Identify numerical columns (excluding the label column)\n",
    "    numerical_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
    "    if 'label' in numerical_cols:\n",
    "        numerical_cols.remove('label')\n",
    "    \n",
    "    # Handle missing values - separately for numerical and categorical columns\n",
    "    if numerical_cols:\n",
    "        df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].mean())\n",
    "    \n",
    "    if categorical_cols:\n",
    "        for col in categorical_cols:\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    \n",
    "    # One-hot encode categorical data\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    if categorical_cols:\n",
    "        encoded_cats = encoder.fit_transform(df[categorical_cols])\n",
    "        encoded_df = pd.DataFrame(encoded_cats, index=df.index)\n",
    "        \n",
    "        # Drop original categorical columns and join encoded ones\n",
    "        df = df.drop(columns=categorical_cols)\n",
    "        df = pd.concat([df, encoded_df], axis=1)\n",
    "    \n",
    "    # Scale numerical features\n",
    "    scaler = StandardScaler()\n",
    "    features = df.drop(columns=['label'], errors='ignore') if 'label' in df.columns else df\n",
    "    df_scaled = scaler.fit_transform(features)\n",
    "    \n",
    "    # Create sequences\n",
    "    X, y = [], []\n",
    "    for i in range(len(df_scaled) - sequence_length):\n",
    "        X.append(df_scaled[i:i+sequence_length])\n",
    "        y.append(1 if 'label' in df.columns and df['label'].iloc[i+sequence_length] == 1 else 0)\n",
    "    \n",
    "    return np.array(X), np.array(y), scaler, encoder if categorical_cols else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training function\n",
    "def train_model(model, train_loader, val_loader, epochs=59, lr=0.00676, device='cpu'):\n",
    "    \"\"\"\n",
    "    Train the LSTM model with early stopping\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Early stopping parameters\n",
    "    patience = 35\n",
    "    best_val_acc = 0\n",
    "    counter = 0\n",
    "    best_model = None\n",
    "    \n",
    "    # For plotting\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        train_acc = 100 * correct / total\n",
    "        avg_train_loss = train_loss/len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_acc = 100 * correct / total\n",
    "        avg_val_loss = val_loss/len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model = model.state_dict().copy()\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(f'Early stopping at epoch {epoch+1}')\n",
    "                break\n",
    "    \n",
    "    # Load best model\n",
    "    if best_model:\n",
    "        model.load_state_dict(best_model)\n",
    "    \n",
    "    # Plot training and validation metrics\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accs, label='Train Accuracy')\n",
    "    plt.plot(val_accs, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation function\n",
    "def evaluate_model(model, test_loader, device='cpu'):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test set\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # For confusion matrix\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Store predictions and labels for confusion matrix\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    true_neg, false_pos, false_neg, true_pos = cm.ravel()\n",
    "    \n",
    "    precision = true_pos / (true_pos + false_pos) if (true_pos + false_pos) > 0 else 0\n",
    "    recall = true_pos / (true_pos + false_neg) if (true_pos + false_neg) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Normal', 'Anomaly'],\n",
    "                yticklabels=['Normal', 'Anomaly'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=['Normal', 'Anomaly']))\n",
    "    \n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define objective function for Optuna\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Objective function for hyperparameter optimization\n",
    "    \"\"\"\n",
    "    # Hyperparameters to optimize\n",
    "    hidden_size = trial.suggest_int('hidden_size', 15, 70)\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 5)\n",
    "    batch_size = trial.suggest_int('batch_size', 15, 400)\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.9)\n",
    "    sequence_length = trial.suggest_categorical('sequence_length', [10, 20, 40, 60])\n",
    "    lr = trial.suggest_float('lr', 0.001, 0.01)\n",
    "    \n",
    "    # Create model with suggested hyperparameters\n",
    "    input_size = X_train.shape[2]\n",
    "    model = LSTMModel(input_size, hidden_size, num_layers, dropout)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Create data loaders with suggested batch size\n",
    "    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.LongTensor(y_train))\n",
    "    val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.LongTensor(y_val))\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    # Train model\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(10):  # Reduced epochs for optimization\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Evaluate model\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Dataset preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig</th>\n",
       "      <th>type</th>\n",
       "      <th>i/f_name</th>\n",
       "      <th>i/f_dir</th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "      <th>proto</th>\n",
       "      <th>appi_name</th>\n",
       "      <th>proxy_src_ip</th>\n",
       "      <th>Modbus_Function_Code</th>\n",
       "      <th>Modbus_Transaction_ID</th>\n",
       "      <th>service</th>\n",
       "      <th>s_port</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.496714</td>\n",
       "      <td>-0.138264</td>\n",
       "      <td>0.647689</td>\n",
       "      <td>1.523030</td>\n",
       "      <td>-0.234153</td>\n",
       "      <td>-0.234137</td>\n",
       "      <td>UDP</td>\n",
       "      <td>0.767435</td>\n",
       "      <td>-0.469474</td>\n",
       "      <td>0.542560</td>\n",
       "      <td>-0.463418</td>\n",
       "      <td>HTTP</td>\n",
       "      <td>0.241962</td>\n",
       "      <td>-1.913280</td>\n",
       "      <td>-1.724918</td>\n",
       "      <td>-0.562288</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.012831</td>\n",
       "      <td>0.314247</td>\n",
       "      <td>-0.908024</td>\n",
       "      <td>-1.412304</td>\n",
       "      <td>1.465649</td>\n",
       "      <td>-0.225776</td>\n",
       "      <td>ICMP</td>\n",
       "      <td>-1.424748</td>\n",
       "      <td>-0.544383</td>\n",
       "      <td>0.110923</td>\n",
       "      <td>-1.150994</td>\n",
       "      <td>HTTP</td>\n",
       "      <td>-0.600639</td>\n",
       "      <td>-0.291694</td>\n",
       "      <td>-0.601707</td>\n",
       "      <td>1.852278</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.013497</td>\n",
       "      <td>-1.057711</td>\n",
       "      <td>0.822545</td>\n",
       "      <td>-1.220844</td>\n",
       "      <td>0.208864</td>\n",
       "      <td>-1.959670</td>\n",
       "      <td>TCP</td>\n",
       "      <td>0.196861</td>\n",
       "      <td>0.738467</td>\n",
       "      <td>0.171368</td>\n",
       "      <td>-0.115648</td>\n",
       "      <td>FTP</td>\n",
       "      <td>-1.478522</td>\n",
       "      <td>-0.719844</td>\n",
       "      <td>-0.460639</td>\n",
       "      <td>1.057122</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.343618</td>\n",
       "      <td>-1.763040</td>\n",
       "      <td>0.324084</td>\n",
       "      <td>-0.385082</td>\n",
       "      <td>-0.676922</td>\n",
       "      <td>0.611676</td>\n",
       "      <td>TCP</td>\n",
       "      <td>0.931280</td>\n",
       "      <td>-0.839218</td>\n",
       "      <td>-0.309212</td>\n",
       "      <td>0.331263</td>\n",
       "      <td>SSH</td>\n",
       "      <td>-0.479174</td>\n",
       "      <td>-0.185659</td>\n",
       "      <td>-1.106335</td>\n",
       "      <td>-1.196207</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.812526</td>\n",
       "      <td>1.356240</td>\n",
       "      <td>-0.072010</td>\n",
       "      <td>1.003533</td>\n",
       "      <td>0.361636</td>\n",
       "      <td>-0.645120</td>\n",
       "      <td>UDP</td>\n",
       "      <td>1.538037</td>\n",
       "      <td>-0.035826</td>\n",
       "      <td>1.564644</td>\n",
       "      <td>-2.619745</td>\n",
       "      <td>HTTP</td>\n",
       "      <td>0.087047</td>\n",
       "      <td>-0.299007</td>\n",
       "      <td>0.091761</td>\n",
       "      <td>-1.987569</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       orig      type  i/f_name   i/f_dir       src       dst proto  \\\n",
       "0  0.496714 -0.138264  0.647689  1.523030 -0.234153 -0.234137   UDP   \n",
       "1 -1.012831  0.314247 -0.908024 -1.412304  1.465649 -0.225776  ICMP   \n",
       "2 -0.013497 -1.057711  0.822545 -1.220844  0.208864 -1.959670   TCP   \n",
       "3  0.343618 -1.763040  0.324084 -0.385082 -0.676922  0.611676   TCP   \n",
       "4  0.812526  1.356240 -0.072010  1.003533  0.361636 -0.645120   UDP   \n",
       "\n",
       "   appi_name  proxy_src_ip  Modbus_Function_Code  Modbus_Transaction_ID  \\\n",
       "0   0.767435     -0.469474              0.542560              -0.463418   \n",
       "1  -1.424748     -0.544383              0.110923              -1.150994   \n",
       "2   0.196861      0.738467              0.171368              -0.115648   \n",
       "3   0.931280     -0.839218             -0.309212               0.331263   \n",
       "4   1.538037     -0.035826              1.564644              -2.619745   \n",
       "\n",
       "  service    s_port      hour    minute    second  label  \n",
       "0    HTTP  0.241962 -1.913280 -1.724918 -0.562288      1  \n",
       "1    HTTP -0.600639 -0.291694 -0.601707  1.852278      0  \n",
       "2     FTP -1.478522 -0.719844 -0.460639  1.057122      0  \n",
       "3     SSH -0.479174 -0.185659 -1.106335 -1.196207      0  \n",
       "4    HTTP  0.087047 -0.299007  0.091761 -1.987569      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and explore data\n",
    "# Replace this with your actual data loading code\n",
    "# For example:\n",
    "# df = pd.read_csv('your_dataset.csv')\n",
    "print(\"Loading data...\")\n",
    "\n",
    "# For demonstration, let's create a synthetic dataset\n",
    "# In a real notebook, you would load your actual data here\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "n_features = 16\n",
    "\n",
    "# Create synthetic features\n",
    "features = ['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto', \n",
    "            'appi_name', 'proxy_src_ip', 'Modbus_Function_Code', \n",
    "            'Modbus_Transaction_ID', 'service', 's_port', 'hour', 'minute', 'second']\n",
    "\n",
    "# Create a synthetic DataFrame\n",
    "df = pd.DataFrame(np.random.randn(n_samples, len(features)), columns=features)\n",
    "\n",
    "# Add some categorical features\n",
    "df['proto'] = np.random.choice(['TCP', 'UDP', 'ICMP'], n_samples)\n",
    "df['service'] = np.random.choice(['HTTP', 'DNS', 'FTP', 'SSH'], n_samples)\n",
    "\n",
    "# Add a label column (0 for normal, 1 for anomaly)\n",
    "# Let's say 10% of the data are anomalies\n",
    "df['label'] = np.random.choice([0, 1], n_samples, p=[0.9, 0.1])\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"Dataset preview:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset shape: (1000, 17)\n",
      "\n",
      "Data types:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "orig                     float64\n",
       "type                     float64\n",
       "i/f_name                 float64\n",
       "i/f_dir                  float64\n",
       "src                      float64\n",
       "dst                      float64\n",
       "proto                     object\n",
       "appi_name                float64\n",
       "proxy_src_ip             float64\n",
       "Modbus_Function_Code     float64\n",
       "Modbus_Transaction_ID    float64\n",
       "service                   object\n",
       "s_port                   float64\n",
       "hour                     float64\n",
       "minute                   float64\n",
       "second                   float64\n",
       "label                      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data exploration\n",
    "print(\"\\nDataset shape:\", df.shape)\n",
    "print(\"\\nData types:\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "orig                     0\n",
       "type                     0\n",
       "i/f_name                 0\n",
       "i/f_dir                  0\n",
       "src                      0\n",
       "dst                      0\n",
       "proto                    0\n",
       "appi_name                0\n",
       "proxy_src_ip             0\n",
       "Modbus_Function_Code     0\n",
       "Modbus_Transaction_ID    0\n",
       "service                  0\n",
       "s_port                   0\n",
       "hour                     0\n",
       "minute                   0\n",
       "second                   0\n",
       "label                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values:\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    894\n",
       "1    106\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class distribution\n",
    "print(\"\\nClass distribution:\")\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize class distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x='label', data=df)\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Class (0=Normal, 1=Anomaly)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing data...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPreprocessing data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m sequence_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m----> 4\u001b[0m X, y, scaler, encoder \u001b[38;5;241m=\u001b[39m preprocess_data(df, sequence_length\u001b[38;5;241m=\u001b[39msequence_length)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, y shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass distribution in y: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mbincount(y)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[18], line 42\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[0;34m(df, sequence_length)\u001b[0m\n\u001b[1;32m     40\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m     41\u001b[0m features \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01melse\u001b[39;00m df\n\u001b[0;32m---> 42\u001b[0m df_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(features)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Create sequences\u001b[39;00m\n\u001b[1;32m     45\u001b[0m X, y \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/utils/_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    319\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1083\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1084\u001b[0m             (\n\u001b[1;32m   1085\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1093\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   1094\u001b[0m         )\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1097\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:878\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 878\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartial_fit(X, y, sample_weight)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:914\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[1;32m    883\u001b[0m \n\u001b[1;32m    884\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    913\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 914\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m    915\u001b[0m     X,\n\u001b[1;32m    916\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    917\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES,\n\u001b[1;32m    918\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    919\u001b[0m     reset\u001b[38;5;241m=\u001b[39mfirst_call,\n\u001b[1;32m    920\u001b[0m )\n\u001b[1;32m    921\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    545\u001b[0m ):\n\u001b[1;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \n\u001b[1;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    614\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/base.py:469\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Set or check the `feature_names_in_` attribute.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \n\u001b[1;32m    451\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03m       should set `reset=False`.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reset:\n\u001b[0;32m--> 469\u001b[0m     feature_names_in \u001b[38;5;241m=\u001b[39m _get_feature_names(X)\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m feature_names_in \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    471\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names_in_ \u001b[38;5;241m=\u001b[39m feature_names_in\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:2279\u001b[0m, in \u001b[0;36m_get_feature_names\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m   2277\u001b[0m \u001b[38;5;66;03m# mixed type of string and non-string is not supported\u001b[39;00m\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m types:\n\u001b[0;32m-> 2279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   2280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names are only supported if all input features have string names, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut your input has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as feature name / column name types. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you want feature names to be stored and validated, you must convert \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthem all to strings, by using X.columns = X.columns.astype(str) for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2284\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample. Otherwise you can remove feature / column names from your input \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata, or convert them all to a non-string data type.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2286\u001b[0m     )\n\u001b[1;32m   2288\u001b[0m \u001b[38;5;66;03m# Only feature names of all strings are supported\u001b[39;00m\n\u001b[1;32m   2289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m types[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type."
     ]
    }
   ],
   "source": [
    "# Preprocess data\n",
    "print(\"\\nPreprocessing data...\")\n",
    "sequence_length = 20\n",
    "X, y, scaler, encoder = preprocess_data(df, sequence_length=sequence_length)\n",
    "\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "print(f\"Class distribution in y: {np.bincount(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test set: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance the training data\n",
    "print(\"\\nBalancing dataset...\")\n",
    "X_train_balanced, y_train_balanced = balance_dataset(X_train, y_train)\n",
    "print(f\"Balanced training set: {X_train_balanced.shape}, {y_train_balanced.shape}\")\n",
    "print(f\"Class distribution after balancing: {np.bincount(y_train_balanced)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nUsing device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter optimization with Optuna\n",
    "print(\"\\nStarting hyperparameter optimization...\")\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=10)  # Reduced for demonstration, use 100 for full optimization\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f\"\\nBest hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model with best hyperparameters\n",
    "input_size = X_train.shape[2]\n",
    "model = LSTMModel(\n",
    "    input_size=input_size,\n",
    "    hidden_size=best_params['hidden_size'],\n",
    "    num_layers=best_params['num_layers'],\n",
    "    dropout=best_params['dropout']\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = best_params['batch_size']\n",
    "train_dataset = TensorDataset(torch.FloatTensor(X_train_balanced), torch.LongTensor(y_train_balanced))\n",
    "val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.LongTensor(y_val))\n",
    "test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.LongTensor(y_test))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "print(\"\\nTraining model...\")\n",
    "model = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=59,  # As specified in the document\n",
    "    lr=best_params['lr'],\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "print(\"\\nEvaluating model...\")\n",
    "accuracy, precision, recall, f1 = evaluate_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and preprocessing objects\n",
    "print(\"\\nSaving model and preprocessing objects...\")\n",
    "torch.save(model.state_dict(), 'lstm_anomaly_detection_model.pth')\n",
    "\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "if encoder:\n",
    "    with open('encoder.pkl', 'wb') as f:\n",
    "        pickle.dump(encoder, f)\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
